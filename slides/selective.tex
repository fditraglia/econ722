%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Optimal Inference After Model Selection (Fithian et al., 2017)}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{frame}{How Statistics is Done In Reality}

  \begin{block}{Step 1: Selection -- Decide what questions to ask.}
    ``The analyst chooses a statistical model for the data at hand, and formulates testing, estimation, or other problems in terms of unknown aspects of that model.''
  \end{block}

  \begin{block}{Step 2: Inference -- Answer the Questions.}
   ``The analyst investigates the chosen problems using the data and the selected model.''
  \end{block}

  \begin{alertblock}{Problem -- ``Data-snooping''}
    Standard techniques for (frequentist) statistical inference assume that we choose our questions \alert{before} observing the data.  
  \end{alertblock}

\end{frame}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}
  \frametitle{Simple Example: ``File Drawer Problem''}

  \begin{block}{$Y_i \sim \mbox{iid N}(\mu_i, 1)$ for $i=1, \dots, n$}
  \begin{itemize}
    \item I want to know which $\mu_i \neq 0$, but I'm busy and $n$ is big.
    \item My RA looks at each $Y_i$ and finds the ``interesting'' ones, namely $\widehat{\mathcal{I}} =\left\{ i\colon |Y_i|>1 \right\}$.
    \item I test $H_{0,i}\colon \mu_i = 0$ against the two-sided alternative at the 5\% significance level for each $i \in \widehat{\mathcal{I}}$.
  \end{itemize}
\end{block}

  \begin{alertblock}{Two Questions}
    \begin{enumerate}
      \item What is the probability of falsely rejecting $H_{0,i}$?
      \item Among all $H_{0,i}$ that I test, what fraction are false rejections? 
    \end{enumerate}
  \end{alertblock}

\end{frame}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}
  \frametitle{Simple Example: ``File Drawer Problem''}

  \small

  \begin{align*}
    \mathbb{P}_{H_{0,i}}(\{\mbox{Reject } H_{0,i}\}) &= \mathbb{P}_{H_{0,i}}(\{\mbox{Test } H_{0,i} \}\cap \{ \mbox{Reject } H_{0,i} \})\\
    &= \mathbb{P}_{H_{0,i}}(\{\mbox{Reject } H_{0,i}\} |\{\mbox{Test } H_{0,i}\})\mathbb{P}_{H_{0,i}}(\{\mbox{Test } H_{0,i}\})\\
    &= \mathbb{P}_{H_{0,i}}\left(\{|Y_i| > 1.96\}|\{|Y_i|>1\} \right) \mathbb{P}_{H_{0,i}}(\{|Y_i|>1\})\\
    &= \frac{2 \Phi(-1.96)}{2 \Phi(-1)} \times 2 \Phi(-1)\\
    &\approx 0.16 \times 0.32 \approx 0.05
  \end{align*}

  \vspace{-1em}

  \begin{align*}
  \mathbb{P}_{H_{0,i}}(\{\mbox{Reject } H_{0,i}\} |\{\mbox{Test } H_{0,i}\}) &= \mathbb{P}_{H_{0,i}}\left(\{|Y_i| > 1.96\}|\{|Y_i|>1\} \right)\\
  &= \frac{\Phi(-1.96)}{\Phi(-1)} \approx 0.16
  \end{align*}

\end{frame}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}
  \frametitle{Simple Example: ``File Drawer Problem''}

  \begin{block}{Conditional vs.\ Unconditional Type I Error Rates}
  \begin{itemize}
    \item The \alert{conditional} probability of falsely rejecting $H_{0,i}$, given that I have tested it, is about 0.16.
    \item The \alert{unconditional} probability of falsely rejecting $H_{0,i}$ is 0.05 since I only test a false null with probability $0.32$.
  \end{itemize}
\end{block}

\begin{block}{Idea for Post-Selection Inference}
  Control the Type I Error Rate \alert{conditional on selection}: ``The answer must be valid, given that the question was asked.''
\end{block}


\end{frame}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}
  \frametitle{Simple Example: ``File Drawer Problem''}


  \begin{block}{Conditional Type I Error Rate}
  Solve $\mathbb{P}_{H_{0,i}}\left( \{|Y_i| > c\} | \{|Y_i|>1\}\right) = 0.05$ for $c$.
\end{block}

  \begin{align*}
    \mathbb{P}_{H_{0,i}}\left( \{|Y_i| > c\} | \{|Y_i|>1\}\right) &= \frac{\Phi(-c)}{\Phi(-1)} = 0.05\\
    c &= -\Phi^{-1}\big(\Phi(-1) \times 0.05\big)\\
    c &\approx 2.41 
  \end{align*}

  \vspace{-2em}

  \begin{alertblock}{Notice:}
  To account for the first-stage selection step, we need a larger critical value: 2.41 vs.\ 1.96. This means the test is less powerful.
\end{alertblock}


\end{frame}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}
  \frametitle{Selective Inference vs.\ Sample-Splitting}

  \begin{block}{Classical Inference}
    Control the Type I error under model $M$: $\mathbb{P}_{M,H_0}(\mbox{reject } H_0) \leq \alpha$.
  \end{block}

  \begin{block}{Selective Inference}
    Control the Type I error under model $M$, \alert{given} that $M$ and $H_0$ were selected: $\mathbb{P}_{M,H_0}\big(\mbox{reject } H_0|\{M,H_0 \mbox{ selected}\}\big) \leq \alpha$.
  \end{block}

  \begin{block}{Sample-Splitting}
    Use different datasets to choose $(M, H_0)$ and carry out inference: $\mathbb{P}_{M,H_0}\big(\mbox{reject } H_0|\{M,H_0 \mbox{ selected}\}\big) = \mathbb{P}_{M,H_0}(\mbox{reject }H_0)$.
  \end{block}


\end{frame}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}
  \frametitle{Selective Inference in Exponential Family Models}

  \footnotesize
  
  \begin{block}{Questions}
  \begin{enumerate}
    \item Recipe for selective inference in realistic examples?
    \item How to construct the ``best'' selective test in a given example?
    \item How does selective inference compare to sample-splitting?
  \end{enumerate}
\end{block}
 
\begin{block}{Fithian, Sun \& Taylor (2017)}
  \begin{itemize}
    \item Use classical theory for exponential family models (Lehmann \& Scheff\'e).
    \item Computational procedure for UMPU selective test/CI after arbitrary model/hypothesis selection.
    \item Sample-splitting is typically inadmissible (wastes information).
    \item Example: post-selection inference for high-dimensional regression
  \end{itemize}
\end{block}

\end{frame}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}
  \frametitle{A Prototype Example of Selective Inference}
  \framesubtitle{This is my own example, but uses the same idea that underlies Fithian et al.}
  \small
 
  \begin{itemize}
    \item Choose between models M1 and M2 based on parameter $\delta$. 
      \begin{itemize} 
        \item If $\delta \neq 0$, choose M1 
        \item If $\delta = 0$, choose M2
        \item E.g.\ $\delta$ is the endogeneity of $X$, M1 is IV and M2 is OLS
  \end{itemize}
\item Observe $Y_\delta \sim N(\delta, 1)$ and use this to choose a model.
  \begin{itemize}
    \item Selection Event: $A \equiv \left\{ |Y_\delta| >c \right\}$, for some critical value $c$ 
    \item If $A$, then choose M1. Otherwise, choose M2.
  \end{itemize}
\item After choosing a model, carry out inference for $\beta$.
  \begin{itemize}
    \item Under a particular model $M$, $Y_\beta \sim N(\beta,1)$
    \item $\beta$ is a \emph{model-specific} parameter
  \end{itemize}

  \end{itemize}

  
  


\end{frame}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

